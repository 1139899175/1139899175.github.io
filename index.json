[{"categories":null,"content":"hadoop完全分布式部署 编号 hostname IP 1 master 192.168.18.128 2 slave1 192.168.18.129 3 slave2 192.168.18.130 ","date":"2022-06-12","objectID":"/second_post/:0:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#hadoop完全分布式部署"},{"categories":null,"content":"Linux环境设置 设置主机名 hostnamectl set-hostname [主机名] 绑定主机名与IP地址 编辑/etc/hosts vim /etc/hosts 关闭防火墙 关闭防火墙 systemctl stop firewall 停用防火墙 systemctl disable firewall SSH免密登录 ssh-keygen ssh-copy-id ","date":"2022-06-12","objectID":"/second_post/:1:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#linux环境设置"},{"categories":null,"content":"Java安装 卸载系统openjdk rpm -qa | greap jave rpm -e --nodeps java..... 解压jdk安装包 tar -zxvf /opt/softawre/jdk..... -C /usr/local/src ll /usr/local/src 配置环境变量 修改全局环境变量 vi /etc/profile 最后两行加入：export JAVA_HOME=/usr/local/src/jdk :export PATH=$PATH:$JAVA_HOME/bin 保存退出 source /etc/profile echo $JAVA_HOME 修改用户环境变量 vim /home/hadoop/.bashrc 最后两行两行加入：export JAVA_HOME=/usr/local/src/jdk :export PATH=$PATH:$JAVA_HOME/bin 保存退出 source /home/hadoop/.bashrc echo $JAVA_HOME ","date":"2022-06-12","objectID":"/second_post/:2:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#java安装"},{"categories":null,"content":"hadoop安装 解压安装包 tar -zxvf ~/hadoop..... -C /usr/local/src 改名:mv /usr/local/src/hadoop-2.7.1.tar.gz/ /usr/local/src/hadoop 配置环境变量 vi /etc/profile 最后加入：export HADOOP_HOME=/usr/local/src/hadoop :export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin 修改目录所有者 chown -R hadoop:hadoop /usr/local/src 检查用户所有者是否为hadoop：；ll /usr/local/src 配置hadoop文件 修改hadoop-env.sh cd /usr/local/src/hadoop/etc/hadoop/ vim hadoop-env.sh exoprt JAVA_HOME=/usr/local/src/java hdfs-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003edfs.namenode.name.dir\u003c/name\u003e \u003cvalue\u003efile:/usr/local/src/hadoop/dfs/name\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.datanode.data.dir\u003c/name\u003e \u003cvalue\u003efile:/usr/local/src/hadoop/dfs/data\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003edfs.replication\u003c/name\u003e \u003cvalue\u003e3\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e yarn-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.address\u003c/name\u003e \u003cvalue\u003emaster:8032\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.scheduler.address\u003c/name\u003e \u003cvalue\u003emaster:8030\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.resource-tracker.address\u003c/name\u003e \u003cvalue\u003emaster:8031\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.admin.address\u003c/name\u003e \u003cvalue\u003emaster:8033\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.resourcemanager.webapp.address\u003c/name\u003e \u003cvalue\u003emaster:8088\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux-services\u003c/name\u003e \u003cvalue\u003emapreduce_shuffle\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eyarn.nodemanager.aux\u0002services.mapreduce.shuffle.class\u003c/name\u003e \u003cvalue\u003eorg.apache.hadoop.mapred.ShuffleHandler\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e mapred-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003emapreduce.framework.name\u003c/name\u003e \u003cvalue\u003eyarn\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.address\u003c/name\u003e \u003cvalue\u003emaster:10020\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003emapreduce.jobhistory.webapp.address\u003c/name\u003e \u003cvalue\u003emaster:19888\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e core-site.xml \u003cconfiguration\u003e \u003cproperty\u003e \u003cname\u003efs.defaultFS\u003c/name\u003e \u003cvalue\u003ehdfs://192.168.150.81:9000\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003eio.file.buffer.size\u003c/name\u003e \u003cvalue\u003e131072\u003c/value\u003e \u003c/property\u003e \u003cproperty\u003e \u003cname\u003ehadoop.tmp.dir\u003c/name\u003e \u003cvalue\u003efile:/usr/local/src/hadoop/tmp\u003c/value\u003e \u003c/property\u003e \u003c/configuration\u003e slaves slave1 slave2 ​ 启动完之后 slave1 slave2 datanode 没开启 ​ 1.检查JPShadoop是否节点都正常启动 2.删除/usr/loacl/src/hadoop/dfs/data/current/VERSION文件后重启 ","date":"2022-06-12","objectID":"/second_post/:3:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#hadoop安装"},{"categories":null,"content":"hive 出问题打不开关闭安全模式 hdfs dfsadmine -safemode leave ","date":"2022-06-12","objectID":"/second_post/:0:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#hive"},{"categories":null,"content":"zookeeper 出问题后 1.确认文件 2.删除/usr/local/src/zookeeper/data/ 后 echo (数字) \u003e /usr/local/src/zookeeper/data/myid 再 source /etc/profile 3.确认端口是否占用（2181）netstat -apn | grep 2181 有占用就删除 kill -9 (进程号) ","date":"2022-06-12","objectID":"/second_post/:1:0","series":null,"tags":null,"title":"Second_post","uri":"/second_post/#zookeeper"}]